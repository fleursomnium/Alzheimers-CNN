{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow\n",
    "# ! pip install kagglehub\n",
    "# ! pip install psutil\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # to surpress the CUDA warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 16\n"
     ]
    }
   ],
   "source": [
    "# check how many cp we are working with\n",
    "print(f\"Number of CPU cores available: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/gitpod/.cache/kagglehub/datasets/uraninjo/augmented-alzheimer-mri-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# importing the data\n",
    "import kagglehub\n",
    "\n",
    "# download latest version\n",
    "path = kagglehub.dataset_download(\"uraninjo/augmented-alzheimer-mri-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 files belonging to 4 classes.\n",
      "Found 33984 files belonging to 4 classes.\n",
      "Original Train Size: 4480 images\n",
      "Augmented Train Size: 23788 images\n",
      "Total Train Size: 28268 images\n",
      "Original Validation Size: 1920 images\n",
      "Augmented Validation Size: 10196 images\n",
      "Total Validation Size: 12116 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:34:28.205198: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Directories for Original and Augmented datasets\n",
    "original_dir = os.path.join(path, 'OriginalDataset')\n",
    "augmented_dir = os.path.join(path, 'AugmentedAlzheimerDataset')\n",
    "\n",
    "def load_and_split_data(directory, img_size=(224, 224), batch_size=32):\n",
    "    # Load all images without batching\n",
    "    dataset = image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        batch_size=None  # Load all images as individual items\n",
    "    )\n",
    "\n",
    "    # Calculate dataset size and split\n",
    "    dataset_size = sum(1 for _ in dataset)\n",
    "    train_size = int(0.7 * dataset_size)\n",
    "\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "\n",
    "    # Apply batching and prefetching\n",
    "    train_dataset = train_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Load and split Original dataset\n",
    "original_train, original_val = load_and_split_data(original_dir)\n",
    "\n",
    "# Load and split Augmented dataset\n",
    "augmented_train, augmented_val = load_and_split_data(augmented_dir)\n",
    "\n",
    "# Combine the train and validation datasets\n",
    "train_dataset = original_train.concatenate(augmented_train)\n",
    "val_dataset = original_val.concatenate(augmented_val)\n",
    "\n",
    "# Print dataset sizes in terms of individual samples\n",
    "print(f\"Original Train Size: {sum(1 for _ in original_train.unbatch())} images\")\n",
    "print(f\"Augmented Train Size: {sum(1 for _ in augmented_train.unbatch())} images\")\n",
    "print(f\"Total Train Size: {sum(1 for _ in train_dataset.unbatch())} images\")\n",
    "\n",
    "print(f\"Original Validation Size: {sum(1 for _ in original_val.unbatch())} images\")\n",
    "print(f\"Augmented Validation Size: {sum(1 for _ in augmented_val.unbatch())} images\")\n",
    "print(f\"Total Validation Size: {sum(1 for _ in val_dataset.unbatch())} images\")\n",
    "\n",
    "# Save train and validation datasets for use in the training part\n",
    "train_dataset_path = \"train_dataset.tfrecord\"\n",
    "val_dataset_path = \"val_dataset.tfrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:44:29.281514: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731617076.039569    4628 service.cc:148] XLA service 0x7ff02c008240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731617076.039741    4628 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1731617076.062171    4628 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 38/884\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42:27\u001b[0m 12s/step - accuracy: 0.4769 - loss: 1.1759"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "\n",
    "# Define ConvNeXt model\n",
    "def create_convnext_model(input_shape=(224, 224, 3), num_classes=4):\n",
    "    \"\"\"Define and return a ConvNeXt model.\"\"\"\n",
    "    base_model = ConvNeXtTiny(\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        weights='imagenet'  # Use pre-trained weights\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze the base model layers\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Use a distributed strategy for multi-GPU training\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Create and compile the model inside the strategy scope\n",
    "    model = create_convnext_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {results[1]*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
